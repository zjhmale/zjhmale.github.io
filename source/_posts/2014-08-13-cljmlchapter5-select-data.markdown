---
layout: post
title: "cljmlchapter5-select data"
date: 2014-08-13 09:44:20 +0800
comments: true
categories: clojure ml
---

在之前的章节中，我们学习了**人工神经网络(ANNs)**以及如何用它们来有效地对非线性样本数据进行建模分析。至此我们已经讨论过好几个可以对给定训练数据集进行建模分析的机器学习技术了。在这一章中，我们将会从如何从样本数据中选择合适的特征的方面探讨以下几个议题：

* 我们会学习一些用于评估和量化指定出来的模型对给定的训练数据集建模的准确性。这些技术将会对于扩展或者调试一个已经训练好的模型非常有帮助。
* 我们会探索`clj-ml`这个库从而量化分析一个给定的机器学习模型。
* 到本章末尾时，我们会结合模型评估技术，实现一个垃圾邮件分类器。

**机器学习诊断**通常是用来描述一个测试过程，这个测试过程在执行时可以深入了解到一个机器学习内部什么在正常工作而什么不在正常工作。在诊断过程中获得的信息有助于我们提高给定机器学习模型的性能。通常情况下，在构建一个机器学习模型的过程中，最好可以并行地为这个模型指定一个诊断过程。构建一个模型诊断过程可能会花费和构建模型本身一样多的时间，但是非常值得去花这些时间去构建这个诊断过程，因为在它的帮助下可以快速的决定该如何对现有的模型进行修改和调整以获得更高的学习能力。因此从另一方面来说，构建一个诊断系统反而可以帮助我们节省调试和改进一个指定好的机器学习模型的时间。

另一个在机器学习领域中有趣的观点是说，假如我们不知道我们试图去建模拟合的数据的性质，我们就不能架设任何一种机器学习模型去拟合这些样本数据。这个公理也被称作**没有免费午餐**理论，可以总结如下：

>"假如无法得到关于一个学习算法性质的先验知识和，任何学习算法都不能说比其他的算法更好或者更烂(甚至是随机猜测)。"

## 理解欠拟合与过拟合

在之前的章节中，我们讨论了在制定一个机器学习模型的时候如何最小化所示函数的误差值。这的确是易于评估模型的总体误差变小，但是一个很小的误差通常来说并不能保证一个模型很好的拟合了给定的训练数据。所以在这一章中我们将会回顾和学习*过拟合*与*欠拟合*的概念。

对于一个预估模型来说，假如在预测时有很大的误差，那么就认为是欠拟合的情况。理想情况下，我们需要尽可能地减小模型的误差。然而，一个损失函数产生的误差很小的模型也未必可以准确地理解隐藏在给定特征之间的基本关系。而且，模型可能还会记住给定的训练数据集，这很有可能会导致模型也会对随机噪声进行建模和拟合。在过分学习了噪声的情况下，也被称作是过拟合了。一个过拟合模型最常见的症状就是可以很好地对已经学习过的样本数据做出准确的预测。但是在面对一个从来没有见到过的新的样本数据时却无法得到正确的结果。根据偏置-方差分解(_Bias-Variance Decomposition_)，假设我们有K个数据集，每个数据集都是从一个分布$$p(t,x)$$中独立的抽取出来的(t代表要预测的变量，x代表特征变量)。对于每个数据集D，我们都可以在其基础上根据学习算法来训练出一个模型$$y(x;D)$$来。在不同的数据集上进行训练可以得到不同的模型。学习算法的性能是根据在这K个数据集上训练得到的K个模型的平均性能来衡量的，亦即：

$$E_{D}[(y(x;D)-h(x))^{2}] = (E_{D}[y(x;D)]-h(x))^{2} + E_{D}[(y(x;D)-E_{D}[y(x;D)])^{2}]$$

其中第一项是偏差项，第二项是方差项，其中的x表示满足样本分布的随机变量。

所以可以看到一个欠拟合的模型存在**高偏差**，一个过拟合模型则具**高方差**。

假如我们要对单自变量和单因变量的数据集进行建模，那么理想情况下，这个模型不仅要能很好地拟合训练数据，对于没有在训练数据集中出现的新样本也要有很强的泛华能力。

在一个欠拟合模型中因变量随着自变量变化的趋势如下图所示：

<center>
	<img src="/images/cljml/chap5/image1.png">
</center>

在上图中，红色的叉表示的是训练数据集中得数据点。就像图中所示，一个欠拟合模型会存在较大的误差，所以我们需要选择合适的特征以及使用正则化技术来减小这个误差。

另一方面，假如一个模型总的误差值非常小的话也可能会出现过拟合的情况，从而使得预估模型没有办法对没有见过的数据进行准确的预测输出。一个过拟合模型的图像如下图所示：

<center>
	<img src="/images/cljml/chap5/image2.png">
</center>

如上图所示，预估模型为了的得到一个很小的总误差，从而过度学习了训练数据，从而对于新的数据没有办法走出正确地响应。

一个很好地拟合了训练样本数据的模型不但有比较小的总误差值，而且对于之前没有见到过的样本数据也能有很强的泛华能力。一个适当拟合的模型可以近似如下图所示：

<center>
	<img src="/images/cljml/chap5/image3.png">
</center>

人工神经网络对于给定的样本数据就可能出现欠拟合或者是过拟合的情况。比如一个神经网络隐含层的层数很少，并且隐含层中的节点也很少，那么就有可能会欠拟合，而如果一个神经网络中隐含层的层数太多或者隐含层中节点数过多就会出现过拟合。

## 评估模型

我们可以通过将因变量随自变量变化的趋势画出来的方法来判断模型是否过拟合或者欠拟合。但是当有大量的特征出现的时候，我们已经没有办法在二维图像中描绘这种趋势了，我们需要一种更好的可视化方法去判断一个模型对已有训练数据的拟合情况，以及对未知数据的泛华能力。

我们可以通过对不同的样布集来分别确定损失函数的值的方式来评估一个训练好的机器学习模型。因此我们需要将给定的数据切割成两份-一份用来做训练，而另一份用来做验证。后者的子集也被称作是模型的测试集。

然后利用$$N_{test}$$数量的样本作为测试集来计算模型损失度函数的值。这让我们可以用之前没有见到过的数据来衡量模型的总误差。这里用$$J_{test}(\hat{y})$$这一项表示评估模型$$\hat{y}$$用测试集计算出来的损失函数值，这一项也叫做这个训练后模型的**测试误差**。而在训练时产生的总误差叫做**训练误差**，并且用$$J_{train}(\hat{y})$$这一项表示。一个线性回归模型的测试误差可以用如下等式来计算：

$$J_{test}(\hat{y}) = \frac{1}{N_{test}}\sum_{i=1}^{N_{test}}(\hat{y}(X_{i})-Y_{i})^{2}$$

类似的，二分类模型中得测试误差也可以表达为如下形式：

$$J_{test}(\hat{y}) = \frac{1}{N_{test}}\sum_{i=1}^{N_{test}}err(\hat{y}(X_{i}), Y_{i}) \\
where \; err(\hat{y}(X_{i}), Y_{i}) = 1 \; if \; \hat{y}(X_{i}) \geq 0.5 \\
and \; err(\hat{y}(X_{i}), Y_{i}) = 0 \; if \; \hat{y}(X_{i}) < 0.5$$

确定模型的特征从而让测试误差减小的问题也叫做**模型选择**或者**特征选择**。当然为了避免过拟合，我们还必须要衡量模型在训练数据集之外的泛化能力。测试误差本身就是对模型在训练数据集之外的泛化误差的一种乐观估计。然而我们还是需要衡量模型在未见过数据上的泛化误差。假如这个模型在非训练集数据上也表现出很低的误差，我们可以基本断定模型没有对训练数据过拟合。这个过程叫做**交叉验证**。

因此，为了保证模型可以在没有见过的数据上也表现的很好，我们还需要一个额外的数据集，也被叫做**交叉验证集**。交叉验证集中样本的数量用$$N_{cv}$$这一项表示。典型情况下，样本数据需要被划分成训练集，测试集和交叉验证集，而且训练集中样本的数量要远大于测试集和交叉验证集。

泛化误差，或者说是交叉验证误差$$J_{cv}(\hat{y})$$确定了预估模型对未知数据拟合能力的性能。需要注意的是，在使用测试集和交叉测试集的时候，我们并没有去更新和修改模型本身。我们会在本章后面的部分深入的学习交叉验证，在后面的学习我们将会看到交叉验证是如何通过一些样本数据来决定一个模型的特征选择的。

举个例子，假如我们在训练数据集中有100个样本，我们需要将这些样本数据分成三个子集。前60个样本会被用来作为训练数据使得模型可以对数据很好的拟合。剩下的后面40个样本，其中20个会作为交叉验证集来评价模型，而最后的20个样本会作为测试集来测试经过交叉验证后的模型。

对于分类问题，展示一个分类器精度的很好的方法就是*混淆矩阵*。这种展示方法通常用来可视化一个基于监督学习算法分类器的分类性能。矩阵中的每一列代表某一类样本经过给定分类器中预测的结果，而每一行代表的是样本真正的类别。混淆矩阵也被称作训练完后的分类器的**应变矩阵**或者**误差矩阵**。

举例来讲解一下混淆矩阵，假如要用分类器做一个二分类，那么这个分类器的混淆矩阵会如下面所示：

<center>
	<img src="/images/cljml/chap5/image4.png">
</center>

在混淆矩阵中，预测出来的类别用竖直列来表示，而真实的列别使用横向行来表示。在上面的例子中，总共有100个样本，然而只有A类中的45个样本和B类中的10个样本被分类器正确分类了。A类中15个样本被分类到了B类，而B类中有30个样本被分类器分类到了A类，显然这是一个性能很差的分类器。

让我们来看另一个分类器的混淆矩阵，这个分类器使用了同样的样本数据，如下所示：

<center>
	<img src="/images/cljml/chap5/image5.png">
</center>

在上面这个混淆矩阵中，分类区对所有B类样本的分类预测结果都是正确地，并且仅仅只有5个A类的样本被错误地分到了B类。因此这个分类器模型相对于之前的那个更好地理解了两个类的特新与差别。所以在实际情况中，我们必须尽可能地让混淆矩阵中除了对角线元素以外的其他位置上元素的值都逼近于0。

## 理解特征选择

正如之前提到的，我们必须为我们的模型从样本数据中选取一套合适的特征。我们可以使用交叉验证机制来根据训练数据确定一组特征，会在下文中详细解释。

对于不同特征变量组合成的特征集合，我们都要用确定这个模型在使用某一组特征集时产生的训练误差和交叉验证误差。例如，我们可能会利用因变量构造高阶多项式作为新的特征。我们根据不同特征集中多项式的最高阶次为自变量，分别计算不同特征集的训练误差和交叉验证误差。我们可以画出这两个误差随着特征集中多项式最高次的不同变化的趋势图，如下所示：

<center>
	<img src="/images/cljml/chap5/image6.png">
</center>

根据上图所示，我们就可以根据$$J_{train}$$和$$J_{cv}$$的变化趋势来选取最合适的特征集。假如一个模型出入上图的左侧，那么这个模型有较高的训练误差和交叉验证误差，那么认为这个模型是对训练数据欠拟合的。另一方面，在上图的右侧的模型虽然训练误差非常小，但是交叉验证的误差很大，一般来说此时这个模型已经过拟合了。一般是选取两个误差都相对较小的时候对应的那一组特征集。

## 调整正则化系数

为了更好地拟合训练数据，我们可以使用正则化系数来避免过拟合问题。对于模型表现出来的行为，必须为给定模型选择一个合适的正则化系数值$$\lambda$$。可以注意到如果正则化系数值过高可能会导致过高的训练误差，这是我们不希望看到的。我们可以以正则化系数值为因变量，画出训练误差和交叉验证误差随之变化的曲线，如下所示：

<center>
	<img src="/images/cljml/chap5/image7.png">
</center>

如上图所示，我们可以通过修正正则化系数从而减小训练误差和交叉验证误差。假如一个模型两个误差都很高，那么我们就要考虑是否要减小正则化系数值直到两个误差对于给定的样本数据都有显著的减小量。

## 理解学习曲线

另一种有效衡量机器学习模型性能的方法是使用学习曲线。一个**学习曲线**本质上是描绘出了一个模型的误差随着对应的训练样本数量变化的趋势。例如，一个模型的训练误差和交叉验证误差的学习曲线可能会如下图所示：

<center>
	<img src="/images/cljml/chap5/image8.png">
</center>

学习曲线可以被用来诊断一个欠拟合或者是过拟合的模型。例如，随着训练样本数量的增加，我们可以观察到训练误差迅速增大并且最终收敛至靠近交叉验证误差值附近的位置。并且最终这个模型的两个误差值都很大。假如一个模型随训练样本数变化误差的变化情况像上面描述的那样，那么认为这个模型是欠拟合的，它的学习曲线可能会如下图所示：

<center>
	<img src="/images/cljml/chap5/image9.png">
</center>

另一方面，一个模型的训练误差随着训练样本数量的增加也可能增长得很缓慢，并且最终收敛到的位置的值和交叉验证误差值仍有很大的偏差，并没有收敛到交叉验证误差值附近。这样的模型就认为是过拟合了，其学习曲线可能如下图所示：

<center>
	<img src="/images/cljml/chap5/image10.png">
</center>

因此，学习曲线是进行交叉验证时一个很好的辅助工具，可以很好地确定机器学习模型中哪一部分没有正常工作，机器学习模型中哪一部分需要进行修改。

